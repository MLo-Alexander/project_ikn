{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b59f329-af0f-4134-b5f0-26e233c5d6c3",
   "metadata": {},
   "source": [
    "## CAPSTONE PROJECT: TWITTER SENTIMENT ANALYSIS ON INDONESIAN CAPITAL RELOCATION PLAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a6f47-9845-415f-a147-c3c2b6dcf388",
   "metadata": {},
   "source": [
    "### This project is organized in 4 notebooks:\n",
    "<ul>\n",
    "<li>Notebook 1: scraping twitter tweets</li>\n",
    "<li>Notebook 2: Data cleaning and EDA</li>\n",
    "<li>Notebook 3: Preprocessing and Modeling 1: IndoBert sentiment analysis</li>\n",
    "<li>Notebook 4 (on Google Colab): Modeling 2, which consists of the following tasks: <\\li>\n",
    "        <ul>\n",
    "        <li>- attempt to fine-tune IndoBenchmark IndoBert model</li>\n",
    "        <li>- evaluating Bert multilingual model's performance</li>\n",
    "        <li>- topic classification with IndoBert GPT2-small</li>\n",
    "        \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd9e92-77e4-4090-b37c-7b7d9dfa9d2a",
   "metadata": {},
   "source": [
    "Notebook 4 is accessible on [Google Colab](https://colab.research.google.com/drive/1-YByOO9JaoM5d9Feyd_vfaIQF4kJbu9M#scrollTo=LRNJPxMre_J1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1300ffe-26be-4a27-8d89-8bcc534d82ea",
   "metadata": {},
   "source": [
    "### This is Notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f8c76-686b-4022-a449-96926a1df3f8",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3c3bd1-efa2-40e0-92e9-0237d00f9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, get_scorer, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268974d-84ad-4cfe-8bf3-fc5c9b22246d",
   "metadata": {},
   "source": [
    "### Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa452ca4-9e2a-49f2-a0be-9771b043e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets_df = pd.read_csv('labeled_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461ec08f-18c2-44e3-9977-cd8ce9122b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8622 entries, 0 to 8621\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   processed_tweets  8622 non-null   object \n",
      " 1   label             8622 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 134.8+ KB\n"
     ]
    }
   ],
   "source": [
    "modeling_data =labeled_tweets_df[['processed_tweets','label']]\n",
    "modeling_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d3e5928-6057-456d-8aa7-19b736155b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establilsh X and y\n",
    "\n",
    "X = modeling_data['processed_tweets']\n",
    "y = modeling_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9dae920-de6e-44cd-bd08-29c05011c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e4cad07-2d68-46e8-a86d-e9c00d1535e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sarahlintang/IndoBERT were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer and model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sarahlintang/IndoBERT\")\n",
    "model_sl = AutoModel.from_pretrained(\"sarahlintang/IndoBERT\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7775b5e-0fa8-4127-a384-957fe91a7390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b735caf-d2b1-41b0-a732-93ce5cf5e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tokenizer to tweet column\n",
    "\n",
    "tokenized = modeling_data['processed_tweets'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaa1dcd1-70d5-4387-bae5-6710b5519252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73a043db-304c-4d46-8704-44392868752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add padding\n",
    "\n",
    "padded = [i + [0]*(max_len-len(i)) for i in tokenized.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e28d0fe-8dc0-41fa-9092-d928984257bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish inputs ids and get last hidden states to fit into classification models\n",
    "\n",
    "input_ids = torch.tensor(np.array(padded))  \n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model_sl(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b5828a6-0373-43e1-993a-b36837250975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish features (X) for modeling\n",
    "\n",
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ae60964-8513-4c04-805e-12a8c0797f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establsih labels (y)\n",
    "\n",
    "labels = modeling_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88eb3eb3-b8eb-4827-a953-32f9be912b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff743b-b3e2-4a95-b70b-bedeb907ef10",
   "metadata": {},
   "source": [
    "### Model 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d179091b-4b9c-4616-9dc8-faa0467ac178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate naive bayes model\n",
    "\n",
    "params_nb = {'alpha': [0.0001,0.1,10]}\n",
    "model_nb = MultinomialNB()\n",
    "grid_nb = GridSearchCV(nb, param_grid=params_nb, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "113a56ed-1dc4-4639-b5b8-4def94e811ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Normalizing', MinMaxScaler()),\n",
       "                ('MultinomialNB', MultinomialNB())])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit naive bayes model\n",
    "\n",
    "pipe_nb = Pipeline([('Normalizing',MinMaxScaler()),('MultinomialNB',MultinomialNB())])\n",
    "pipe_nb.fit(train_features, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fee5300b-736f-452a-b4f7-027824e105ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NaiveBayes classifier score: 0.670 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# naive bayes cross val score:\n",
    "\n",
    "scores_nb = cross_val_score(pipe_nb, train_features, train_labels)\n",
    "print(\"Multinomial NaiveBayes classifier score: %0.3f (+/- %0.2f)\" % (scores_nb.mean(), scores_nb.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2947f715-9806-4257-b43d-ba0a2064830a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0016875-5e7b-4e96-85f4-8aa27df8f605",
   "metadata": {},
   "source": [
    "### Model 2. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "063462cb-a85b-4286-8ae2-4d514d00b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate svc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "params_svc = {\"C\": np.linspace(0.0001, 0.1, 10)}\n",
    "svc= SVC(max_iter=500, class_weight='balanced')\n",
    "cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_svc = GridSearchCV(svc, param_grid=params_svc, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c8be0410-7b03-44d2-b61f-7218574c8ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Normalizing', MinMaxScaler()), ('grid_svc', SVC())])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit svc model\n",
    "\n",
    "pipe_svc = Pipeline([('Normalizing',MinMaxScaler()),('grid_svc', SVC())])\n",
    "pipe_svc.fit(train_features, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "acbbc669-50b8-4049-87da-8670321a7d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier average score: 0.724 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "# svc cross val score:\n",
    "\n",
    "scores_svc = cross_val_score(pipe_svc, train_features, train_labels)\n",
    "print(\"SVM classifier average score: %0.3f (+/- %0.2f)\" % (scores_svc.mean(), scores_svc.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6e78f-2c41-48a9-baea-b574f4e2fc70",
   "metadata": {},
   "source": [
    "**Observation:**<br>\n",
    "Looking at F1 score, it is observed that SVM classifier is the winner with score of 72.5% and Naive Bayes is performing at 65.9%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7722f3c-7aa6-47de-b7db-31eed81e3b3e",
   "metadata": {},
   "source": [
    "### Model 3. Bert sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "584e0f65-ba31-4504-8fda-498aa0f00463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\.conda\\envs\\dsi-sg-37\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb5c3dae-e318-4867-a809-0f879b6cb7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e23962a2c24adcb952306806b9ef9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68afa5887704b8494888bcce3c3f4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff27dd2ae02541e391a812b48297dbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a657ba1f668b44a9b13951fadbd9cbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_bert = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d4c2331-ad66-4320-aecf-18a83ca2f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction using bert sentiment analysis\n",
    "\n",
    "pred_bert = []\n",
    "for i in modeling_data['processed_tweets']:\n",
    "    pred = pipe_bert(i)\n",
    "    pred_bert.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "546b533b-8eb5-415e-9e18-1388bf6ddaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\.conda\\envs\\dsi-sg-37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sensasi gimana ya</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.752638816833...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metaverse bernama jagat merasakan sensasi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.972690463066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metaversa sensasi bernama jagat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.987670481204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tahap metaverse bernama jagat merasakan sensasi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.959913432598...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tahap awalnamun merasakan sensasi metaverse be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.990127384662...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>metaverse jagat diluncurkan sensasi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.987223684787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>metaverse bernama jagat masyarakat merasakan s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.983072876930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>metaverse jagat merasakan sensasi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.984077095985...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nama metaverse jagat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.998415887355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tahap bary merasakan sensasi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.669706046581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>keren metaverse jagat merasakan sensasi semoga...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.981344163417...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>merasakan sensasi metaverse bernama jagat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.955915689468...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>keren banget guys ngerasain sensasi metaverse ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.975513815879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>peran tni al pengawalan menjaga keamanan wilay...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.858380317687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dirancang inklusif lapisan masyarakat\\n\\nuntuk...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.970037043094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ppu  satgas ops polda kaltim regu a melaksanak...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.988829314708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gambaran bernama jagat menarik \\n\\nkompas meng...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.985528111457...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>membangun bendungan sepaku semoi penyediaan ai...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.919034063816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>meme celetukan ngocol warganet</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.704155266284...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>buka ruang kreasi generasi muda seniman ayo ge...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.993527591228...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     processed_tweets  label  \\\n",
       "0                                   sensasi gimana ya    1.0   \n",
       "1           metaverse bernama jagat merasakan sensasi    1.0   \n",
       "2                     metaversa sensasi bernama jagat    1.0   \n",
       "3     tahap metaverse bernama jagat merasakan sensasi    1.0   \n",
       "4   tahap awalnamun merasakan sensasi metaverse be...    1.0   \n",
       "5                 metaverse jagat diluncurkan sensasi    1.0   \n",
       "6   metaverse bernama jagat masyarakat merasakan s...    1.0   \n",
       "7                   metaverse jagat merasakan sensasi    1.0   \n",
       "8                                nama metaverse jagat    0.0   \n",
       "9                        tahap bary merasakan sensasi    1.0   \n",
       "10  keren metaverse jagat merasakan sensasi semoga...    1.0   \n",
       "11          merasakan sensasi metaverse bernama jagat    1.0   \n",
       "12  keren banget guys ngerasain sensasi metaverse ...    1.0   \n",
       "13  peran tni al pengawalan menjaga keamanan wilay...    0.0   \n",
       "14  dirancang inklusif lapisan masyarakat\\n\\nuntuk...    1.0   \n",
       "15  ppu  satgas ops polda kaltim regu a melaksanak...    0.0   \n",
       "16  gambaran bernama jagat menarik \\n\\nkompas meng...    1.0   \n",
       "17  membangun bendungan sepaku semoi penyediaan ai...    0.0   \n",
       "18                     meme celetukan ngocol warganet   -1.0   \n",
       "19  buka ruang kreasi generasi muda seniman ayo ge...    1.0   \n",
       "\n",
       "                                      predicted_label  \n",
       "0   [{'label': 'POSITIVE', 'score': 0.752638816833...  \n",
       "1   [{'label': 'NEGATIVE', 'score': 0.972690463066...  \n",
       "2   [{'label': 'NEGATIVE', 'score': 0.987670481204...  \n",
       "3   [{'label': 'NEGATIVE', 'score': 0.959913432598...  \n",
       "4   [{'label': 'NEGATIVE', 'score': 0.990127384662...  \n",
       "5   [{'label': 'NEGATIVE', 'score': 0.987223684787...  \n",
       "6   [{'label': 'NEGATIVE', 'score': 0.983072876930...  \n",
       "7   [{'label': 'NEGATIVE', 'score': 0.984077095985...  \n",
       "8   [{'label': 'NEGATIVE', 'score': 0.998415887355...  \n",
       "9   [{'label': 'NEGATIVE', 'score': 0.669706046581...  \n",
       "10  [{'label': 'NEGATIVE', 'score': 0.981344163417...  \n",
       "11  [{'label': 'NEGATIVE', 'score': 0.955915689468...  \n",
       "12  [{'label': 'NEGATIVE', 'score': 0.975513815879...  \n",
       "13  [{'label': 'NEGATIVE', 'score': 0.858380317687...  \n",
       "14  [{'label': 'NEGATIVE', 'score': 0.970037043094...  \n",
       "15  [{'label': 'NEGATIVE', 'score': 0.988829314708...  \n",
       "16  [{'label': 'NEGATIVE', 'score': 0.985528111457...  \n",
       "17  [{'label': 'NEGATIVE', 'score': 0.919034063816...  \n",
       "18  [{'label': 'NEGATIVE', 'score': 0.704155266284...  \n",
       "19  [{'label': 'NEGATIVE', 'score': 0.993527591228...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_data['predicted_label']=pred_bert\n",
    "modeling_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fc567-c0e7-4d23-8cec-d921d2ca62cb",
   "metadata": {},
   "source": [
    "**Observation:**<br>\n",
    "Looks like most of them are mis-labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc6b58-6e5a-4368-abd1-17a731e2d178",
   "metadata": {},
   "source": [
    "### Model 5. Fine-tuning IndoBert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ec245-2ed6-4551-b10b-06aae981389d",
   "metadata": {},
   "source": [
    "### Model 6. Bert multilingual pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff70a3-689b-43b1-868c-00a92f5e4d0f",
   "metadata": {},
   "source": [
    "### Model 7. IndoBert GPT2-small-indonesian-522M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae92fb2-52b0-46cd-8d59-9c9171898488",
   "metadata": {},
   "source": [
    "Models 5, 6 and 7 are accessible on [Google Colab](https://colab.research.google.com/drive/1-YByOO9JaoM5d9Feyd_vfaIQF4kJbu9M#scrollTo=sZVDIx-VEkdd&uniqifier=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9753a5ce-b017-4367-81b2-182b86d3cffc",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12f603-d743-4b1e-a799-43b0392a73bc",
   "metadata": {},
   "source": [
    "IndoBert models perform decently well with unseen data on the following 2 tasks:<br>\n",
    "(i) sentiment analysis with [IndoBert](https://huggingface.co/sarahlintang/IndoBERT)\n",
    "(ii) topic classification with [IndoBert GPT2-small](https://huggingface.co/cahya/gpt2-small-indonesian-522M?text=Pulau+Dewata+sering+dikunjungi)<br>\n",
    "\n",
    "These models perform much better than Bert multilingual model trained on 102 languages including Indonesian, with F1 score comparison of 0.725 (IndoBert) vs 0.343 (multilingual Bert).<br>\n",
    "The IndoBert model needs to be supported by Indonesian language python pre-processing packages such as nltk indonesian and Sastrawi stemmer.\n",
    "\n",
    "From network visualization on Gephi, it can be identified which twitter users are most active and have most connections. The visualization also reveals who are interested in the capital relocation project and who are the main actors within the project's social network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b2f67-4ed3-40b8-add0-e935dfb650ea",
   "metadata": {},
   "source": [
    "### Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfae5f-c9f1-45a5-afe8-682a083c2838",
   "metadata": {},
   "source": [
    "- The project analysis is based on data collected within limited amount of data and limited period of time.<br>\n",
    "- The project does not consider sentiments from non-twitter users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ca6c0-ea7b-4720-a11d-b272aff607a9",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b09a2c7-0a40-4fcd-871c-09f2c9d56c7e",
   "metadata": {},
   "source": [
    "Building up on this project, further investigations can be conducted to:<br>\n",
    "    - investigate twitter social network and their political interests<br>\n",
    "    - identify social media buzzers and paid sentiments that they twitted<br>\n",
    "    - extend data to cover tweets from 2019 when the capital relocation plan was first announced<br>\n",
    "    - explore other Indonesian language pretrained models and other foreign language models<br>\n",
    "    - fine-tune models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ee32a-97e0-4665-9282-bd17fe7eed55",
   "metadata": {},
   "source": [
    "### Links:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c95d755-dad0-4ca7-a87f-a46cb1ab76f4",
   "metadata": {},
   "source": [
    "To [Tableau interactive dashboard presentation slides](https://public.tableau.com/app/profile/m.alexander8473/viz/capitalrelocationtwitteranalysis/presentation?publish=yes)<br>\n",
    "To [Google Colab](https://colab.research.google.com/drive/1-YByOO9JaoM5d9Feyd_vfaIQF4kJbu9M#scrollTo=LRNJPxMre_J1) notebook 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04555c-905c-474a-8d31-3a1e07f87aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
